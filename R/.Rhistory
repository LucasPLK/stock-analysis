View(df_qtd_nulos %>% group_by(indicador) %>%
summarise(TotalNulos = sum(qtd_nulos), TotalColuna=sum(qtd_total)) %>%
arrange(desc(TotalNulos)))
library(tidyr)
library(dplyr)
source("functions.R") # minhas funções definidas em um arquivo a parte
# Carregamento dos dados
df <- read.csv('../data/data.csv')
## Limpeza do dataset
df[df == '-'] <- NA
df[df == '-%'] <- NA
for(i in 1:ncol(df)) {
# remoção dos simbolos de percentual
df[ , i] <- gsub('%', '', df[ , i])
df[ , i] <- gsub(',', '.', df[ , i])
}
# faz o trim dos textos
df <- data.frame(lapply(df, trimws), stringsAsFactors = FALSE)
# transforma celulas vazias em NA
df[df == ''] <- NA
i <-c(4:13)
df[ , i] <- apply(df[ , i],
2, # 2 significa operar sobre colunas, 1 operar sobre as linhas
function(x) as.numeric(as.character(x)))
sapply(df, class) # verificando o tipo de cada coluna
View(df[-100:-1, ])
# verifico a quantidade de nulos que existem por indicar em cada ano
df_qtd_nulos = check_nans_by_indicator_and_year(df,
unique(df$Indicador),
c('ATUAL', 'X2021', 'X2020',
'X2019', 'X2018',
'X2017', 'X2016', 'X2015',
'X2014', 'X2013')
)
#Agrupo os dados por ano e verifico em qual ano tenho mais nulos
View(df_qtd_nulos %>% group_by(anos) %>%
summarise(TotalNulos = sum(qtd_nulos), TotalColuna=sum(qtd_total)) %>%
arrange(desc(TotalNulos)))
#Agrupo os dados por indicador e verifico em qual ano tenho mais nulos
View(df_qtd_nulos %>% group_by(indicador) %>%
summarise(TotalNulos = sum(qtd_nulos), TotalColuna=sum(qtd_total)) %>%
arrange(desc(TotalNulos)))
View(df[-100:-1, ])
library(reshape2)
# reproducible version of your data
mydata = read.csv(text="c1,c2,c3,c4
E,5.76,201,A la vista
E,47530.71,201,A la vista
E,82.85,201,A la vista
L,11376.55,201,A la vista
E,6683.37,203,A la vista
E,66726.52,203,A la vista
E,2.39,203,A la vista
E,79066.07,202,Montoxv_a60d
E,14715.71,202,Montoxv_a60d
E,22661.78,202,Montoxv_a60d
L,81146.25,124,Montoxv_a90d
L,471730.2,124,Montoxv_a186d
E,667812.84,124,Montoxv_a186d", header=TRUE)
View(mydata)
result = dcast(mydata, c1 + c3 ~ c4, value.var="c2", fun.aggregate=sum)
View(mydata)
View(result)
View(df[-100:-1, ])
dcast(df, Ticker ~Indicador, value.var="ATUAL", fun.aggregate = sum)
View(dcast(df, Ticker ~Indicador, value.var="ATUAL", fun.aggregate = sum))
View(dcast(df, Ticker ~ Indicador, value.var="ATUAL", fun.aggregate = sum))
View(dcast(df, Ticker + Setor ~ Indicador, value.var="ATUAL", fun.aggregate = sum))
df_pivot = dcast(df, Ticker + Setor ~ Indicador, value.var="ATUAL", fun.aggregate = sum)
head(df_pivot)
df_pivot.isna()
summary(df_pivot)
sum(complete.cases(df_pivot))
colSums(is.na(df_pivot))
View(colSums(is.na(df_pivot)))
nrow(df_pivot)
df_pivot %>%select(where(~mean(is.na(.)) < 0.1))
View(df_pivot %>%select(where(~mean(is.na(.)) < 0.1)))
library(tidyr)
library(dplyr)
library(reshape2)
source("functions.R") # minhas funções definidas em um arquivo a parte
# Carregamento dos dados
df <- read.csv('../data/data.csv')
## Limpeza do dataset
df[df == '-'] <- NA
df[df == '-%'] <- NA
for(i in 1:ncol(df)) {
# remoção dos simbolos de percentual
df[ , i] <- gsub('%', '', df[ , i])
df[ , i] <- gsub(',', '.', df[ , i])
}
# faz o trim dos textos
df <- data.frame(lapply(df, trimws), stringsAsFactors = FALSE)
# transforma celulas vazias em NA
df[df == ''] <- NA
i <-c(4:13)
df[ , i] <- apply(df[ , i],
2, # 2 significa operar sobre colunas, 1 operar sobre as linhas
function(x) as.numeric(as.character(x)))
sapply(df, class) # verificando o tipo de cada coluna
View(df[-100:-1, ])
# verifico a quantidade de nulos que existem por indicar em cada ano
df_qtd_nulos = check_nans_by_indicator_and_year(df,
unique(df$Indicador),
c('ATUAL', 'X2021', 'X2020',
'X2019', 'X2018',
'X2017', 'X2016', 'X2015',
'X2014', 'X2013')
)
#Agrupo os dados por ano e verifico em qual ano tenho mais nulos
View(df_qtd_nulos %>% group_by(anos) %>%
summarise(TotalNulos = sum(qtd_nulos), TotalColuna=sum(qtd_total)) %>%
arrange(desc(TotalNulos)))
#Agrupo os dados por indicador e verifico em qual ano tenho mais nulos
View(df_qtd_nulos %>% group_by(indicador) %>%
summarise(TotalNulos = sum(qtd_nulos), TotalColuna=sum(qtd_total)) %>%
arrange(desc(TotalNulos)))
#pivot table
df_pivot = dcast(df, Ticker + Setor ~ Indicador, value.var="ATUAL", fun.aggregate = sum)
head(df_pivot)
View(colSums(is.na(df_pivot)))
nrow(df_pivot)
View(df_pivot %>% select(where(~mean(is.na(.)) < 0.1)))
df_pivot_filtered <- df_pivot %>% select(where(~mean(is.na(.)) < 0.1))
ncol(df_pivot), ncol(df_pivot_filtered)
ncol(df_pivot)
ncol(df_pivot_filtered)
View(df_pivot_filtered)
View(df_pivot_filtered)
install.packages('dbscan')
library(factoextra)
library(factoextra)
View(df_pivot_filtered)
# Faço o fill na com a média dos dados do segmento:
df_pivot_filtered %>%
group_by(Ticker, Segmento) %>%
mutate(LPA = case_when(is.na(LPA) ~ mean(LPS, na.rm=TRUE),
TRUE ~ as.numeric(LPA)
)
)
# Faço o fill na com a média dos dados do segmento:
df_pivot_filtered %>%
group_by(Ticker, Setor) %>%
mutate(LPA = case_when(is.na(LPA) ~ mean(LPS, na.rm=TRUE),
TRUE ~ as.numeric(LPA)
)
)
# Faço o fill na com a média dos dados do segmento:
df_pivot_filtered %>%
group_by(Ticker, Setor) %>%
mutate(LPA = case_when(is.na(LPA) ~ mean(LPA, na.rm=TRUE),
TRUE ~ as.numeric(LPA)
)
)
# Faço o fill na com a média dos dados do segmento:
View(df_pivot_filtered %>%
group_by(Ticker, Setor) %>%
mutate(LPA = case_when(is.na(LPA) ~ mean(LPA, na.rm=TRUE),
TRUE ~ as.numeric(LPA)
)
)
)
# Faço o fill na com a média dos dados do segmento:
df_pivot_filtered %>%
group_by(Ticker, Setor) %>%
mutate(LPA = case_when(is.na(LPA) ~ mean(LPA, na.rm=TRUE),
TRUE ~ as.numeric(LPA)
)
)
# Faço o fill na com a média dos dados do segmento:
df_pivot_filtered %>% replace_na(LPA = 0)
# Faço o fill na com a média dos dados do segmento:
df_pivot_filtered$LPA %>% replace_na(0)
df_pivot_filtered
# Faço o fill na com a média dos dados do segmento:
is.na(df_pivot_filtered$LPA)# %>% replace_na(0)
# Faço o fill na com a média dos dados do segmento:
sum(is.na(df_pivot_filtered$LPA))# %>% replace_na(0)
for(i in 3:ncol(df_pivot_filtered)){
df_pivot_filtered[is.na(df_pivot_filtered[,i]), i] <- mean(df_pivot_filtered[,i], na.rm = TRUE)
}
df_pivot_filtered
library(tidyr)
library(dplyr)
library(reshape2)
library(factoextra)
source("functions.R") # minhas funções definidas em um arquivo a parte
# Carregamento dos dados
df <- read.csv('../data/data.csv')
## Limpeza do dataset
df[df == '-'] <- NA
df[df == '-%'] <- NA
for(i in 1:ncol(df)) {
# remoção dos simbolos de percentual
df[ , i] <- gsub('%', '', df[ , i])
df[ , i] <- gsub(',', '.', df[ , i])
}
# faz o trim dos textos
df <- data.frame(lapply(df, trimws), stringsAsFactors = FALSE)
# transforma celulas vazias em NA
df[df == ''] <- NA
i <-c(4:13)
df[ , i] <- apply(df[ , i],
2, # 2 significa operar sobre colunas, 1 operar sobre as linhas
function(x) as.numeric(as.character(x)))
sapply(df, class) # verificando o tipo de cada coluna
View(df[-100:-1, ])
# verifico a quantidade de nulos que existem por indicar em cada ano
df_qtd_nulos = check_nans_by_indicator_and_year(df,
unique(df$Indicador),
c('ATUAL', 'X2021', 'X2020',
'X2019', 'X2018',
'X2017', 'X2016', 'X2015',
'X2014', 'X2013')
)
#Agrupo os dados por ano e verifico em qual ano tenho mais nulos
View(df_qtd_nulos %>% group_by(anos) %>%
summarise(TotalNulos = sum(qtd_nulos), TotalColuna=sum(qtd_total)) %>%
arrange(desc(TotalNulos)))
#Agrupo os dados por indicador e verifico em qual ano tenho mais nulos
View(df_qtd_nulos %>% group_by(indicador) %>%
summarise(TotalNulos = sum(qtd_nulos), TotalColuna=sum(qtd_total)) %>%
arrange(desc(TotalNulos)))
#pivot table
df_pivot = dcast(df, Ticker + Setor ~ Indicador, value.var="ATUAL", fun.aggregate = sum)
head(df_pivot)
df_pivot_filtered <- df_pivot %>% select(where(~mean(is.na(.)) < 0.1))
ncol(df_pivot)
ncol(df_pivot_filtered)
View(df_pivot_filtered)
for(i in 3:ncol(df_pivot_filtered)){
df_pivot_filtered[is.na(df_pivot_filtered[,i]), i] <- mean(df_pivot_filtered[,i], na.rm = TRUE)
}
df_pivot_filtered
install.packages('dbscan')
library(dbscan)
df_pivot_filtered %>% mutate_all(~ifelse(is.na(.x), mean(.x, na.rm = TRUE), .x))
source("~/Documents/MBA/TCC/01-git/stock-analysis/R/EDA.R", echo=TRUE)
df_pivot_filtered %>% mutate_all(~ifelse(is.na(.x), mean(.x, na.rm = TRUE), .x))
View(df_pivot_filtered)
df_pivot_filtered <-df_pivot_filtered %>%
mutate_all(~ifelse(is.na(.x), mean(.x, na.rm = TRUE), .x))
df_pivot_filtered_scaled <- scale(df_pivot_filtered)
df_pivot_filtered_scaled <- scale(df_pivot_filtered[, c(2, ncol(df_pivot_filtered))])
df_pivot_filtered_scaled <- scale(df_pivot_filtered[, c(3, ncol(df_pivot_filtered))])
View(df_pivot_filtered_scaled)
View(df_pivot_filtered_scaled)
ncol(df_pivot_filtered)
df_pivot_filtered_scaled <- scale(df_pivot_filtered[, c(3, ncol(df_pivot_filtered))])
df_pivot_filtered_scaled <- scale(df_pivot_filtered[, c(3, ncol(df_pivot_filtered))])
View(df_pivot_filtered_scaled)
View(df_pivot_filtered_scaled)
df_pivot_filtered[, c(3, ncol(df_pivot_filtered))]
c(3, ncol(df_pivot_filtered)
c(3, ncol(df_pivot_filtered))
c(3, ncol(df_pivot_filtered))
df_pivot_filtered_scaled <- scale(df_pivot_filtered[, c(3:ncol(df_pivot_filtered))])
c(3: ncol(df_pivot_filtered))
df_pivot_filtered_scaled <- scale(df_pivot_filtered[, c(3:ncol(df_pivot_filtered))])
View(df_pivot_filtered_scaled)
View(df_pivot_filtered_scaled)
d <- dbscan::dbscan(df_pivot_filtered_scaled, eps = 0.45, MinPts =  2)
View(d)
View(d)
fviz_cluster(d, customer_prep, geom = "point")
library(factoextra) # visualização de clusters
library(cluster)
fviz_cluster(d, customer_prep, geom = "point")
fviz_cluster(d, df_pivot_filtered_scaled, geom = "point")
d <- dbscan::dbscan(df_pivot_filtered_scaled, eps = 0.8, MinPts =  2)
fviz_cluster(d, df_pivot_filtered_scaled, geom = "point")
d <- dbscan::dbscan(df_pivot_filtered_scaled, eps = 1.8, MinPts =  2)
fviz_cluster(d, df_pivot_filtered_scaled, geom = "point")
View(d)
View(d)
d <- dbscan::dbscan(df_pivot_filtered_scaled, eps = 5, MinPts =  2)
fviz_cluster(d, df_pivot_filtered_scaled, geom = "point")
d <- dbscan::dbscan(df_pivot_filtered_scaled[, c(3, 4)], eps = 5, MinPts =  2)
fviz_cluster(d, df_pivot_filtered_scaled, geom = "point")
fviz_cluster(d, df_pivot_filtered_scaled[, c(3, 4)], geom = "point")
data_for_cluster <- df_pivot_filtered_scaled[, LPA, EBIT]
data_for_cluster <- df_pivot_filtered_scaled[, [LPA, EBIT]]
data_for_cluster <- df_pivot_filtered_scaled[, c(LPA, EBIT)]
data_for_cluster <- df_pivot_filtered_scaled[c(LPA, EBIT)]
data_for_cluster <- df_pivot_filtered_scaled[c('LPA', EBIT)]
data_for_cluster <- df_pivot_filtered_scaled[c('LPA', 'EBIT')]
data_for_cluster <- df_pivot_filtered_scaled %>% select[LPA]
data_for_cluster <- df_pivot_filtered_scaled %>% select['LPA']
data_for_cluster <- df_pivot_filtered_scaled %>% select(LPA)
View(df_pivot_filtered)
data_for_cluster <- df_pivot_filtered_scaled %>% select(LPA)
data_for_cluster <- df_pivot_filtered_scaled %>% select('LPA')
typeof(df_pivot)
typeof(df_pivot_filtered)
typeof(df)
is.data.frame(df)
is.data.frame(df_pivot_filtered_scaled)
is.data.frame(df_pivot_filtered)
data_for_cluster <- df_pivot_filtered %>% select('LPA')
View(data_for_cluster)
View(data_for_cluster)
as.data.frame(df_pivot_filtered_scaled)
df_pivot_filtered_scaled
df_pivot_filtered_scaled <- as.data.frame(scale(df_pivot_filtered[, c(3:ncol(df_pivot_filtered))]))
is.data.frame(df_pivot_filtered_scaled)
data_for_cluster <- df_pivot_filtered %>% select('LPA', 'P/L')
d <- dbscan::dbscan(data_for_cluster, eps = 1.8, MinPts =  2)
fviz_cluster(d, data_for_cluster, geom = "point")
---
title: "R Notebook"
output: html_notebook
---
This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code.
Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Ctrl+Shift+Enter*.
```{r}
plot(cars)
plot(cars)
Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.
When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).
The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.
The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.
knitr::opts_chunk$set(echo = TRUE)
```{r}
library(tidyr)
library(tidyr)
library(dplyr)
library(reshape2)
library(factoextra) # visualização de clusters
library(dbscan)
library(cluster)
library(factoextra) # visualização de clusters
library(dbscan)
library(cluster)
source("functions.R") # minhas funções definidas em um arquivo a parte
source("functions.R") # minhas funções definidas em um arquivo a parte
# Carregamento dos dados
df <- read.csv('../data/data.csv')
## Limpeza do dataset
df[df == '-'] <- NA
df[df == '-%'] <- NA
library(dbscan)
library(cluster)
source("functions.R") # minhas funções definidas em um arquivo a parte
# Carregamento dos dados
df <- read.csv('../data/data.csv')
## Limpeza do dataset
df[df == '-'] <- NA
df[df == '-%'] <- NA
for(i in 1:ncol(df)) {
# remoção dos simbolos de percentual
df[ , i] <- gsub('%', '', df[ , i])
df[ , i] <- gsub(',', '.', df[ , i])
}
library(factoextra) # visualização de clusters
library(dbscan)
library(cluster)
source("functions.R") # minhas funções definidas em um arquivo a parte
# Carregamento dos dados
df <- read.csv('../data/data.csv')
## Limpeza do dataset
df[df == '-'] <- NA
df[df == '-%'] <- NA
for(i in 1:ncol(df)) {
# remoção dos simbolos de percentual
df[ , i] <- gsub('%', '', df[ , i])
df[ , i] <- gsub(',', '.', df[ , i])
}
# faz o trim dos textos
df <- data.frame(lapply(df, trimws), stringsAsFactors = FALSE)
df[df == '-%'] <- NA
for(i in 1:ncol(df)) {
# remoção dos simbolos de percentual
df[ , i] <- gsub('%', '', df[ , i])
df[ , i] <- gsub(',', '.', df[ , i])
}
# faz o trim dos textos
df <- data.frame(lapply(df, trimws), stringsAsFactors = FALSE)
# transforma celulas vazias em NA
df[df == ''] <- NA
i <-c(4:13)
source("functions.R") # minhas funções definidas em um arquivo a parte
# Carregamento dos dados
df <- read.csv('../data/data.csv')
## Limpeza do dataset
df[df == '-'] <- NA
df[df == '-%'] <- NA
for(i in 1:ncol(df)) {
# remoção dos simbolos de percentual
df[ , i] <- gsub('%', '', df[ , i])
df[ , i] <- gsub(',', '.', df[ , i])
}
# faz o trim dos textos
df <- data.frame(lapply(df, trimws), stringsAsFactors = FALSE)
# transforma celulas vazias em NA
df[df == ''] <- NA
i <-c(4:13)
df[ , i] <- apply(df[ , i],
2, # 2 significa operar sobre colunas, 1 operar sobre as linhas
function(x) as.numeric(as.character(x)))
sapply(df, class) # verificando o tipo de cada coluna
df[ , i] <- apply(df[ , i],
2, # 2 significa operar sobre colunas, 1 operar sobre as linhas
function(x) as.numeric(as.character(x)))
sapply(df, class) # verificando o tipo de cada coluna
View(df[-100:-1, ])
View(df[-100:-1, ])
# verifico a quantidade de nulos que existem por indicar em cada ano
df_qtd_nulos = check_nans_by_indicator_and_year(df,
unique(df$Indicador),
c('ATUAL', 'X2021', 'X2020',
'X2019', 'X2018',
'X2017', 'X2016', 'X2015',
'X2014', 'X2013')
)
i <-c(4:13)
df[ , i] <- apply(df[ , i],
2, # 2 significa operar sobre colunas, 1 operar sobre as linhas
function(x) as.numeric(as.character(x)))
sapply(df, class) # verificando o tipo de cada coluna
View(df[-100:-1, ])
# verifico a quantidade de nulos que existem por indicar em cada ano
df_qtd_nulos = check_nans_by_indicator_and_year(df,
unique(df$Indicador),
c('ATUAL', 'X2021', 'X2020',
'X2019', 'X2018',
'X2017', 'X2016', 'X2015',
'X2014', 'X2013')
)
#Agrupo os dados por ano e verifico em qual ano tenho mais nulos
View(df_qtd_nulos %>% group_by(anos) %>%
summarise(TotalNulos = sum(qtd_nulos), TotalColuna=sum(qtd_total)) %>%
arrange(desc(TotalNulos)))
View(df[-100:-1, ])
# verifico a quantidade de nulos que existem por indicar em cada ano
df_qtd_nulos = check_nans_by_indicator_and_year(df,
unique(df$Indicador),
c('ATUAL', 'X2021', 'X2020',
'X2019', 'X2018',
'X2017', 'X2016', 'X2015',
'X2014', 'X2013')
)
#Agrupo os dados por ano e verifico em qual ano tenho mais nulos
View(df_qtd_nulos %>% group_by(anos) %>%
summarise(TotalNulos = sum(qtd_nulos), TotalColuna=sum(qtd_total)) %>%
arrange(desc(TotalNulos)))
#Agrupo os dados por indicador e verifico em qual ano tenho mais nulos
View(df_qtd_nulos %>% group_by(indicador) %>%
summarise(TotalNulos = sum(qtd_nulos), TotalColuna=sum(qtd_total)) %>%
arrange(desc(TotalNulos)))
#Agrupo os dados por indicador e verifico em qual ano tenho mais nulos
View(df_qtd_nulos %>% group_by(indicador) %>%
summarise(TotalNulos = sum(qtd_nulos), TotalColuna=sum(qtd_total)) %>%
arrange(desc(TotalNulos)))
#pivot table
df_pivot = dcast(df, Ticker + Setor ~ Indicador, value.var="ATUAL", fun.aggregate = sum)
View(df[-100:-1, ])
# verifico a quantidade de nulos que existem por indicar em cada ano
df_qtd_nulos = check_nans_by_indicator_and_year(df,
unique(df$Indicador),
c('ATUAL', 'X2021', 'X2020',
'X2019', 'X2018',
'X2017', 'X2016', 'X2015',
'X2014', 'X2013')
)
#Agrupo os dados por ano e verifico em qual ano tenho mais nulos
View(df_qtd_nulos %>% group_by(anos) %>%
summarise(TotalNulos = sum(qtd_nulos), TotalColuna=sum(qtd_total)) %>%
arrange(desc(TotalNulos)))
#Agrupo os dados por indicador e verifico em qual ano tenho mais nulos
View(df_qtd_nulos %>% group_by(indicador) %>%
summarise(TotalNulos = sum(qtd_nulos), TotalColuna=sum(qtd_total)) %>%
arrange(desc(TotalNulos)))
#pivot table
df_pivot = dcast(df, Ticker + Setor ~ Indicador, value.var="ATUAL", fun.aggregate = sum)
head(df_pivot)
View(df[-100:-1, ])
# verifico a quantidade de nulos que existem por indicar em cada ano
df_qtd_nulos = check_nans_by_indicator_and_year(df,
unique(df$Indicador),
c('ATUAL', 'X2021', 'X2020',
'X2019', 'X2018',
'X2017', 'X2016', 'X2015',
'X2014', 'X2013')
)
#Agrupo os dados por ano e verifico em qual ano tenho mais nulos
View(df_qtd_nulos %>% group_by(anos) %>%
summarise(TotalNulos = sum(qtd_nulos), TotalColuna=sum(qtd_total)) %>%
arrange(desc(TotalNulos)))
#Agrupo os dados por indicador e verifico em qual ano tenho mais nulos
View(df_qtd_nulos %>% group_by(indicador) %>%
summarise(TotalNulos = sum(qtd_nulos), TotalColuna=sum(qtd_total)) %>%
arrange(desc(TotalNulos)))
#pivot table
df_pivot = dcast(df, Ticker + Setor ~ Indicador, value.var="ATUAL", fun.aggregate = sum)
head(df_pivot)
df_pivot_filtered <- df_pivot %>% select(where(~mean(is.na(.)) < 0.1))
head(df_pivot)
df_pivot_filtered <- df_pivot %>% select(where(~mean(is.na(.)) < 0.1))
ncol(df_pivot)
ncol(df_pivot)
ncol(df_pivot_filtered)
ncol(df_pivot)
ncol(df_pivot_filtered)
View(df_pivot_filtered)
library(tidyr)
library(dplyr)
library(reshape2)
library(factoextra) # visualização de clusters
library(dbscan)
library(cluster)
source("functions.R") # minhas funções definidas em um arquivo a parte
